{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "uCByOosqzsPbiYUrHPs4ozPA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 20909,
          "status": "ok",
          "timestamp": 1729884825671,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "uCByOosqzsPbiYUrHPs4ozPA",
        "outputId": "f43062ed-672c-494c-adea-7a0c7fde7803",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform openai gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "iSOR20fxSMt_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5218,
          "status": "ok",
          "timestamp": 1729884834148,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "iSOR20fxSMt_",
        "outputId": "86135d0f-c2c4-4364-ee7e-d157b1b500bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
            "Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.3\n"
          ]
        }
      ],
      "source": [
        "! pip3 install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "oXDuOrn5EY3t",
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1729884846894,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "oXDuOrn5EY3t"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "VrblSlWrEehc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1729884850764,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "VrblSlWrEehc",
        "outputId": "ca84179e-d269-4517-aea5-d8df1832e2e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "C2qhnFumEidb",
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1729884853017,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "C2qhnFumEidb"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"lexical-pattern-439216-d8\"  # @param {type:\"string\"}\n",
        "\n",
        "# Only `us-central1` is supported region for Llama 3.2 models using Model-as-a-Service (MaaS).\n",
        "LOCATION = \"us-central1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Vz17DdhlEjZm",
      "metadata": {
        "executionInfo": {
          "elapsed": 262,
          "status": "ok",
          "timestamp": 1729884854588,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "Vz17DdhlEjZm"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"llama3_2_example_bucket\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2e5XVUsyErda",
      "metadata": {
        "executionInfo": {
          "elapsed": 10034,
          "status": "ok",
          "timestamp": 1729884866169,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "2e5XVUsyErda"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ivAxBNAyFJYw",
      "metadata": {
        "executionInfo": {
          "elapsed": 244,
          "status": "ok",
          "timestamp": 1729884881152,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "ivAxBNAyFJYw"
      },
      "outputs": [],
      "source": [
        "credentials, _ = default()\n",
        "auth_request = transport.requests.Request()\n",
        "credentials.refresh(auth_request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "CNLGpxwwFL3l",
      "metadata": {
        "executionInfo": {
          "elapsed": 251,
          "status": "ok",
          "timestamp": 1729884882602,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "CNLGpxwwFL3l"
      },
      "outputs": [],
      "source": [
        "MODEL_LOCATION = \"us-central1\"\n",
        "MAAS_ENDPOINT = f\"{MODEL_LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "    api_key=credentials.token,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cPXRqvQLFO6o",
      "metadata": {
        "executionInfo": {
          "elapsed": 263,
          "status": "ok",
          "timestamp": 1729884884335,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "cPXRqvQLFO6o"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"meta/llama-3.2-90b-vision-instruct-maas\"  # @param {type:\"string\"} [\"meta/llama-3.2-90b-vision-instruct-maas\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Ql4ZooHxFSgR",
      "metadata": {
        "executionInfo": {
          "elapsed": 1818,
          "status": "ok",
          "timestamp": 1729885079438,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "Ql4ZooHxFSgR"
      },
      "outputs": [],
      "source": [
        "max_tokens = 4096\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_ID,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"gs://llama3_2_example_bucket/women dressed casually.webp\"\n",
        "                    },\n",
        "                    \"type\": \"image_url\",\n",
        "                },\n",
        "                {\"text\": \"What’s in this image? Can you describe what she is wearing\", \"type\": \"text\"},\n",
        "            ],\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": \"You are a fashion assistant and you analyse what a person is wearing in the image. In this image, you have:\"},\n",
        "    ],\n",
        "    max_tokens=max_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "68pyP9UhFzDG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1729885077624,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "68pyP9UhFzDG",
        "outputId": "484de93a-4a25-4d5c-bfe2-8cdeded27475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The person in the image is wearing a white t-shirt, light-blue jeans, and white sneakers.\n"
          ]
        }
      ],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1PG34wd5AXc1",
      "metadata": {
        "executionInfo": {
          "elapsed": 507,
          "status": "ok",
          "timestamp": 1729885122513,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "1PG34wd5AXc1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import uuid\n",
        "import tempfile\n",
        "from google.cloud import storage\n",
        "from gtts import gTTS\n",
        "from google.auth.transport import requests\n",
        "from google.auth import default\n",
        "import openai\n",
        "import gradio as gr\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import io\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "\n",
        "max_tokens = 50  # Adjusted for shorter commentary\n",
        "\n",
        "async def upload_file_to_bucket(file_path: str) -> str:\n",
        "    \"\"\"Uploads a file to a Google Cloud Storage bucket.\"\"\"\n",
        "    try:\n",
        "        storage_client = storage.Client()\n",
        "        bucket = storage_client.bucket(BUCKET_NAME)\n",
        "\n",
        "        file_extension = file_path.split(\".\")[-1].lower()\n",
        "        blob_name = f\"analysis_{uuid.uuid4()}.{file_extension}\"\n",
        "\n",
        "        blob = bucket.blob(blob_name)\n",
        "        await asyncio.to_thread(blob.upload_from_filename, file_path)\n",
        "\n",
        "        file_uri = f\"gs://{BUCKET_NAME}/{blob_name}\"\n",
        "        return file_uri\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading file: {e}\")\n",
        "        return None\n",
        "\n",
        "async def process_frame(image_uri):\n",
        "    \"\"\"Processes a video frame using a multimodal LLM.\"\"\"\n",
        "    prompt = \"\"\"\n",
        "    You're a cricket commentator. Describe the current action in one short, exciting sentence (under 10 words).\n",
        "    Focus on key moments and player actions. Keep it brief and engaging.\n",
        "    Keep it flowing.\n",
        "    It is fine to send an empty string as response if the frame doesnt have a any crucial information to share.\n",
        "    \"\"\"\n",
        "\n",
        "    credentials, _ = await asyncio.to_thread(default)\n",
        "    auth_request = requests.Request()\n",
        "    await asyncio.to_thread(credentials.refresh, auth_request)\n",
        "\n",
        "    client = openai.OpenAI(\n",
        "        base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "        api_key=credentials.token,\n",
        "    )\n",
        "    response = await asyncio.to_thread(\n",
        "        client.chat.completions.create,\n",
        "        model=MODEL_ID,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"image_url\": {\"url\": image_uri}, \"type\": \"image_url\"},\n",
        "                    {\"text\": prompt, \"type\": \"text\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "async def text_to_speech(text, lang='en'):\n",
        "    \"\"\"Converts text to speech using gTTS and saves it as an MP3 file.\"\"\"\n",
        "\n",
        "    # Create a gTTS object with the given text and language\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "\n",
        "    # Save the generated speech to a file\n",
        "    file_path = \"output.mp3\"\n",
        "    tts.save(file_path)\n",
        "\n",
        "    # Since gTTS is synchronous, simulate async behavior\n",
        "    await asyncio.sleep(0)  # Simulating an async non-blocking operation\n",
        "\n",
        "    # Read the saved audio content\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "        audio_content = audio_file.read()\n",
        "\n",
        "    return audio_content\n",
        "\n",
        "async def process_video_stream(video_path):\n",
        "    \"\"\"Processes a video stream, generating and yielding commentary with audio and video frames.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_interval = int(fps * 3) // 2  # Process every half second\n",
        "\n",
        "    frame_count = 0\n",
        "    tasks = []\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % frame_interval == 0:\n",
        "                temp_frame_path = f\"temp_frame_{frame_count}.jpg\"\n",
        "                cv2.imwrite(temp_frame_path, frame)\n",
        "\n",
        "                frame_uri = await upload_file_to_bucket(temp_frame_path)\n",
        "                task = asyncio.create_task(process_frame(frame_uri))\n",
        "                tasks.append(task)\n",
        "\n",
        "                os.remove(temp_frame_path)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # Process completed tasks\n",
        "            if tasks:  # Only wait if there are tasks\n",
        "                done, pending = await asyncio.wait(tasks, timeout=0.1, return_when=asyncio.FIRST_COMPLETED)\n",
        "                tasks = list(pending)  # Convert set to list\n",
        "                for task in done:\n",
        "                    commentary = task.result()\n",
        "                    audio_data = await text_to_speech(commentary)\n",
        "\n",
        "                    if audio_data:\n",
        "                        # Save audio to a temporary file\n",
        "                        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio_file:\n",
        "                            temp_audio_file.write(audio_data)\n",
        "                            temp_audio_path = temp_audio_file.name\n",
        "\n",
        "                        yield commentary, temp_audio_path, frame\n",
        "            else:\n",
        "                # If no tasks are processing, just yield the frame\n",
        "                yield None, None, frame\n",
        "\n",
        "            # Simulate real-time processing\n",
        "            await asyncio.sleep(1 / fps)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Process any remaining tasks\n",
        "    for task in asyncio.as_completed(tasks):\n",
        "        commentary = await task\n",
        "        audio_data = await text_to_speech(commentary)\n",
        "\n",
        "        if audio_data:\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio_file:\n",
        "                temp_audio_file.write(audio_data)\n",
        "                temp_audio_path = temp_audio_file.name\n",
        "\n",
        "            yield commentary, temp_audio_path, None\n",
        "\n",
        "async def demo_fn(video_path):\n",
        "    \"\"\"\n",
        "    Processes a video using a multimodal LLM and generates live commentary with audio and video playback.\n",
        "    \"\"\"\n",
        "    async for commentary, audio_path, frame in process_video_stream(video_path):\n",
        "        if frame is not None:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        yield commentary, audio_path, frame\n",
        "\n",
        "# Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=demo_fn,\n",
        "    inputs=gr.File(label=\"Upload Cricket Video\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Live Commentary\"),\n",
        "        gr.Audio(label=\"Audio Commentary\", streaming=True),\n",
        "        gr.Image(label=\"Video Playback\", streaming=True)\n",
        "    ],\n",
        "    title=\"Live Cricket Commentary with AI\",\n",
        "    live=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DubqBvx_AaXr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "DubqBvx_AaXr",
        "outputId": "cd0757e3-7260-471d-c8ab-5f13afa10977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d35b6d7c6a03e1020b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d35b6d7c6a03e1020b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The batter swings hard, unleashing a powerful shot.\n",
            "Babar smashes a six to the boundary.\n",
            "The batsman is hitting a shot.\n",
            "The bowler is delivering the ball.\n",
            "Bowled, oh what a delivery.\n",
            "The bowler is bowling the ball.\n",
            "Babar unleashes a powerful shot to the boundary.\n",
            "Bowled, he's gone for a duck.\n",
            "The bowler is delivering the ball.\n",
            "The batsman swings his bat with all his might.\n",
            "The batsman is in mid-swing, hitting the ball.\n",
            "The batsman is about to hit the ball.\n",
            "The bowler is about to throw the ball.\n",
            "The ball is heading straight for the batsman.\n",
            "Babar smashes a boundary to the mid-wicket region.\n",
            "The ball is flying through the air.\n"
          ]
        }
      ],
      "source": [
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "genai.explorers (Oct 20, 2024, 6:54:43 PM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
